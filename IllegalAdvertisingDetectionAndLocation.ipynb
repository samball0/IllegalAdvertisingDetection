{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4d4be-6ca0-40fd-9dd5-670bd8a698c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import six\n",
    "import time\n",
    "import glob\n",
    "from IPython.display import display\n",
    "\n",
    "from six import BytesIO\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "import MapillaryTools as tools\n",
    "import cv2\n",
    "import folium\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3e50a-6237-498c-927a-52de257fbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, json\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly_express as px\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.io import show\n",
    "from bokeh.plotting import gmap\n",
    "from bokeh.models import GMapOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0cee4-2627-4fbf-abad-b6dfdf2f211d",
   "metadata": {},
   "source": [
    "## Save sequence from Mapillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2ff01-7bee-4fe7-b00f-5f6bfe3fdc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_id ='B2WnFfSoV8DyuNXq7h5vdE'\n",
    "sequence_name = 'test_run'\n",
    "tools.save_images_from_sequence(sequence_id, sequence_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45c5955-fd78-421e-8cd7-403f031357df",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966054c-6e71-4e88-add6-881b9f255bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = r\"C:\\Users\\samly\\Documents\\5.2\\Thesis_Training\\models_full\\research\\object_detection\\inference_graph\\saved_model\"\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.saved_model.load(model_directory)\n",
    "print(model)\n",
    "label_map_path = r\"C:\\Users\\samly\\Documents\\5.2\\Thesis_Training\\models_full\\research\\object_detection\\data\\label_map.pbtxt\"\n",
    "category_index = label_map_util.create_category_index_from_labelmap(label_map_path, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde332a2-f64d-4685-8c0c-a491e39b81bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc8849-ee36-47e8-bf8e-1c60ce8ba6e3",
   "metadata": {},
   "source": [
    "## Find Instances in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa20ff7-cc33-4f9e-a415-47d5151bf119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ClassifierTools as classify\n",
    "import Text_Detection as textTools\n",
    "sequence_name = 'test_run'\n",
    "vinyl_banners = []\n",
    "property_signs = []\n",
    "num_classed = 0\n",
    "for item in os.listdir(sequence_name):\n",
    "    image_id = item.split('.')[0]\n",
    "    image_path = os.path.join(sequence_name, item)\n",
    "    print(\"Classifying {}\".format(image_path))\n",
    "    image, image_np, image_height, image_width = classify.load_image_into_numpy_array(image_path)\n",
    "    output_dict = classify.run_inference_for_single_image(model, image_np)\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=8)\n",
    "\n",
    "    classified_img = Image.fromarray(image_np)\n",
    "    classified_img.save('Classified\\{}.jpg'.format(image_id))\n",
    "    \n",
    "    display(Image.fromarray(image_np))\n",
    "    filenames = []\n",
    "    vinyl_banner = {}\n",
    "    property_sign = {}\n",
    "    for index in range(len(output_dict[\"detection_classes\"])):\n",
    "        if output_dict[\"detection_scores\"][index] > 0.6:\n",
    "            #print(\"{} found in image\".format(category_index[output_dict[\"detection_classes\"][index]][\"name\"]))\n",
    "            x_min = int(output_dict['detection_boxes'][index][0] * image_width)\n",
    "            y_min = int(output_dict['detection_boxes'][index][1] * image_height)\n",
    "            x_max = int(output_dict['detection_boxes'][index][2] * image_width)\n",
    "            y_max = int(output_dict['detection_boxes'][index][3] * image_height)\n",
    "\n",
    "            # Crop detection\n",
    "            cropped_image = tf.image.crop_to_bounding_box(image, x_min, y_min, x_max - x_min, y_max - y_min)\n",
    "\n",
    "            # encode_jpeg encodes a tensor of type uint8 to string\n",
    "            output_image = tf.image.encode_jpeg(cropped_image)\n",
    "            # decode_jpeg decodes the string tensor to a tensor of type uint8\n",
    "            #output_image = tf.image.decode_jpeg(output_image)\n",
    "\n",
    "            score = output_dict[\"detection_scores\"][index] * 100\n",
    "\n",
    "            file_name = r\"Detections/{}_{}_{}.jpg\".format(image_id, category_index[output_dict[\"detection_classes\"][index]][\"name\"], score)\n",
    "            filenames.append(file_name)\n",
    "\n",
    "            writefile = tf.io.write_file(file_name, output_image)\n",
    "\n",
    "            img, img_np, img_height, img_width = classify.load_image_into_numpy_array(file_name)\n",
    "            \n",
    "            # Get location of image\n",
    "            address,lat,lon,epochs = tools.get_location_of_image(image_id)\n",
    "            \n",
    "            # Get timestamp\n",
    "            time = datetime.fromtimestamp(epochs)\n",
    "            \n",
    "            # Detect and Recognise text\n",
    "            text, _ = textTools.detect_and_recognise_text(file_name)\n",
    "            \n",
    "            # Save Relevant Information in dictionaries for each class\n",
    "            if category_index[output_dict[\"detection_classes\"][index]][\"name\"] == \"vinyl banner\":\n",
    "                vinyl_banner[\"image id\"] = image_id\n",
    "                vinyl_banner[\"full_image\"] = classified_img\n",
    "                vinyl_banner[\"detection\"] = img\n",
    "                vinyl_banner[\"confidence\"] = score\n",
    "                vinyl_banner[\"address\"] = address\n",
    "                vinyl_banner[\"text\"] = text\n",
    "                vinyl_banner[\"latitude\"] = lat\n",
    "                vinyl_banner[\"longitude\"] = lon\n",
    "                vinyl_banner[\"filename\"] = file_name\n",
    "                vinyl_banner[\"captured_at\"] = time\n",
    "                vinyl_banners.append(vinyl_banner)\n",
    "            else:\n",
    "                property_sign[\"image id\"] = image_id\n",
    "                property_sign[\"full_image\"] = classified_img\n",
    "                property_sign[\"detection\"] = img\n",
    "                property_sign[\"confidence\"] = score\n",
    "                property_sign[\"address\"] = address\n",
    "                property_sign[\"text\"] = text\n",
    "                property_sign[\"latitude\"] = lat\n",
    "                property_sign[\"longitude\"] = lon\n",
    "                property_sign[\"filename\"] = file_name\n",
    "                property_sign[\"captured_at\"] = time\n",
    "                property_signs.append(property_sign)\n",
    "                \n",
    "    num_classed += 1\n",
    "                \n",
    "print(\"Classified {} images\".format(num_classed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b38cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import HTML\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "def get_thumbnail(path):\n",
    "    path = \"\\\\\\\\?\\\\\"+path # This \"\\\\\\\\?\\\\\" is used to prevent problems with long Windows paths\n",
    "    i = Image.open(path)    \n",
    "    return i\n",
    "\n",
    "def image_base64(im):\n",
    "    if isinstance(im, str):\n",
    "        im = get_thumbnail(im)\n",
    "    with BytesIO() as buffer:\n",
    "        im.save(buffer, 'jpeg')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def full_image_formatter(im):\n",
    "    return f'<img src=\"data:image/jpeg;base64,{image_base64(im)}\"'+'\" width=\"500\" >'\n",
    "\n",
    "def image_formatter(im):\n",
    "    return f'<img src=\"data:image/jpeg;base64,{image_base64(im)}\">'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c59f69f",
   "metadata": {},
   "source": [
    "## Create DataFrame for Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641fb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "df_property_signs = pd.DataFrame(property_signs)\n",
    "HTML(df_property_signs.to_html(formatters={'full_image':full_image_formatter,'detection' : image_formatter}, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinyl_banners = pd.DataFrame(vinyl_banners)\n",
    "HTML(df_vinyl_banners.to_html(formatters={'full_image':full_image_formatter,'detection' : image_formatter}, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad1a7e9",
   "metadata": {},
   "source": [
    "## Filter Out Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49177fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in df_property_signs.iterrows():\n",
    "    for j,row1 in df_property_signs.iterrows():\n",
    "        if i == j:\n",
    "            continue\n",
    "        elif row['image id'] == row1['image id']:\n",
    "            if int(row['confidence']) == int(row1['confidence']):\n",
    "                display(row['detection'])\n",
    "                display(row1['detection'])\n",
    "                df_property_signs.drop(j, inplace=True)\n",
    "            else:\n",
    "                continue\n",
    "        elif abs(row['latitude'] - row1['latitude']) < 0.0006 and abs(row['longitude'] - row1['longitude']) < 0.0006:\n",
    "            base = cv2.imread(row['filename'])\n",
    "            test = cv2.imread(row1['filename'])\n",
    "            \n",
    "            hsv_base = cv2.cvtColor(base, cv2.COLOR_BGR2HSV)\n",
    "            hsv_test = cv2.cvtColor(test, cv2.COLOR_BGR2HSV)\n",
    "            \n",
    "            h_bins = 50\n",
    "            s_bins = 60\n",
    "            histSize = [h_bins, s_bins]\n",
    "            h_ranges = [0, 180]\n",
    "            s_ranges = [0, 256]\n",
    "            ranges = h_ranges + s_ranges\n",
    "            channels = [0, 1]\n",
    "\n",
    "            hist_base = cv2.calcHist([hsv_base], channels, None, histSize, ranges, accumulate=False)\n",
    "            cv2.normalize(hist_base, hist_base, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "            hist_test = cv2.calcHist([hsv_test], channels, None, histSize, ranges, accumulate=False)\n",
    "            cv2.normalize(hist_test, hist_test, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "            \n",
    "            compare_method = cv2.HISTCMP_CORREL\n",
    "\n",
    "            base_test = cv2.compareHist(hist_base, hist_test, compare_method)\n",
    "\n",
    "            print('base_test Similarity = ', base_test)\n",
    "            if base_test > 0.45:\n",
    "                display(row['detection'])\n",
    "                display(row1['detection'])\n",
    "                if row['confidence'] > row1['confidence']:\n",
    "                    df_property_signs.drop(j, inplace=True)\n",
    "                elif row['confidence'] < row1['confidence']:\n",
    "                    df_property_signs.drop(i, inplace=True)\n",
    "                    break\n",
    "                    \n",
    "HTML(df_property_signs.to_html(formatters={'full_image':full_image_formatter,'detection' : image_formatter}, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c66fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in df_vinyl_banners.iterrows():\n",
    "    for j,row1 in df_vinyl_banners.iterrows():\n",
    "        if i == j:\n",
    "            continue\n",
    "        elif row['image id'] == row1['image id']:\n",
    "            if int(row['confidence']) == int(row1['confidence']):\n",
    "                display(row['detection'])\n",
    "                display(row1['detection'])\n",
    "                df_vinyl_banners.drop(i, inplace=True)\n",
    "            else:\n",
    "                continue\n",
    "        elif abs(row['latitude'] - row1['latitude']) < 0.0006 and abs(row['longitude'] - row1['longitude']) < 0.0006:\n",
    "            base = cv2.imread(row['filename'])\n",
    "            test = cv2.imread(row1['filename'])\n",
    "            \n",
    "            hsv_base = cv2.cvtColor(base, cv2.COLOR_BGR2HSV)\n",
    "            hsv_test = cv2.cvtColor(test, cv2.COLOR_BGR2HSV)\n",
    "            \n",
    "            h_bins = 50\n",
    "            s_bins = 60\n",
    "            histSize = [h_bins, s_bins]\n",
    "            h_ranges = [0, 180]\n",
    "            s_ranges = [0, 256]\n",
    "            ranges = h_ranges + s_ranges\n",
    "            channels = [0, 1]\n",
    "\n",
    "            hist_base = cv2.calcHist([hsv_base], channels, None, histSize, ranges, accumulate=False)\n",
    "            cv2.normalize(hist_base, hist_base, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "            hist_test = cv2.calcHist([hsv_test], channels, None, histSize, ranges, accumulate=False)\n",
    "            cv2.normalize(hist_test, hist_test, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "            \n",
    "            compare_method = cv2.HISTCMP_CORREL\n",
    "\n",
    "            base_test = cv2.compareHist(hist_base, hist_test, compare_method)\n",
    "\n",
    "            print('base_test Similarity = ', base_test)\n",
    "            if base_test > 0.45:\n",
    "                display(row['detection'])\n",
    "                display(row1['detection'])\n",
    "                if row['confidence'] > row1['confidence']:\n",
    "                    df_vinyl_banners.drop(j, inplace=True)\n",
    "                    break\n",
    "                elif row['confidence'] < row1['confidence']:\n",
    "                    df_vinyl_banners.drop(i, inplace=True)\n",
    "                    break\n",
    "                    \n",
    "HTML(df_vinyl_banners.to_html(formatters={'full_image':full_image_formatter,'detection' : image_formatter}, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0618de",
   "metadata": {},
   "source": [
    "## Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_property_signs.drop('full_image', axis=1, inplace = True)\n",
    "df_property_signs.drop('image id', axis=1, inplace = True)\n",
    "df_property_signs.drop('latitude', axis=1, inplace = True)\n",
    "df_property_signs.drop('longitude', axis=1, inplace = True)\n",
    "df_property_signs.drop('filename', axis=1, inplace = True)\n",
    "df_property_signs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinyl_banners.drop('full_image', axis=1, inplace = True)\n",
    "df_vinyl_banners.drop('image id', axis=1, inplace = True)\n",
    "df_vinyl_banners.drop('latitude', axis=1, inplace = True)\n",
    "df_vinyl_banners.drop('longitude', axis=1, inplace = True)\n",
    "df_vinyl_banners.drop('filename', axis=1, inplace = True)\n",
    "df_vinyl_banners.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20851520",
   "metadata": {},
   "source": [
    "## Display Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9c261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(df_property_signs.to_html(formatters={'detection' : image_formatter}, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd986cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(df_vinyl_banners.to_html(formatters={'detection' : image_formatter}, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a3f4c",
   "metadata": {},
   "source": [
    "## Plot Findings on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[df_property_signs['latitude'].mean(), df_property_signs['longitude'].mean()], \n",
    "                 zoom_start=15, \n",
    "                 control_scale=True)\n",
    "\n",
    "for i,row in df_property_signs.iterrows():\n",
    "    #Setup the content of the popup\n",
    "    #iframe = folium.IFrame('Text :' + str(row[\"Text\"]))\n",
    "    \n",
    "    #Initialise the popup using the iframe\n",
    "    #popup = folium.Popup(iframe, min_width=300, max_width=300)\n",
    "    \n",
    "    #Add each row to the map\n",
    "    folium.Marker(location=[row['latitude'],row['longitude']],\n",
    "                   icon=folium.Icon(color='darkgreen', icon='')).add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36900a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[df_vinyl_banners['latitude'].mean(), df_vinyl_banners['longitude'].mean()], \n",
    "                 zoom_start=15, \n",
    "                 control_scale=True)\n",
    "\n",
    "for i,row in df_vinyl_banners.iterrows():\n",
    "    #Setup the content of the popup\n",
    "    #iframe = folium.IFrame('Text :' + str(row[\"Text\"]))\n",
    "    \n",
    "    #Initialise the popup using the iframe\n",
    "    #popup = folium.Popup(iframe, min_width=300, max_width=300)\n",
    "    \n",
    "    #Add each row to the map\n",
    "    folium.Marker(location=[row['latitude'],row['longitude']],\n",
    "                   icon=folium.Icon(color='cadetblue', icon='')).add_to(map)\n",
    "map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
